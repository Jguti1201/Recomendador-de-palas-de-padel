{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping de Palas de Pádel  \n",
    "\n",
    "- Este script extrae información de palas desde **Padel Nuestro** usando `requests` y `BeautifulSoup`.  \n",
    "- Primero, obtiene el HTML de cada página de productos y extrae **nombre, precio, atributos y descripción**.  \n",
    "- Para cada pala, accede a su página individual para recopilar más detalles.  \n",
    "- Recorre hasta **35 páginas**, guardando los datos en un archivo `palas.json`.  \n",
    "- Incluye un `time.sleep(1)` para evitar bloqueos por exceso de solicitudes.  \n",
    "- Se recomienda revisar los **términos de uso** del sitio web antes de hacer scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# URL base de las páginas de palas\n",
    "BASE_URL = \"https://www.padelnuestro.com/int/padel-rackets?p={}\"\n",
    "\n",
    "# Encabezados para la solicitud HTTP\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Función para obtener el HTML de la página\n",
    "def get_html(url):\n",
    "    response = requests.get(url, headers=HEADERS, verify=False)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Error al acceder a la página: {response.status_code}\")\n",
    "\n",
    "# Función para extraer los detalles de cada pala\n",
    "def extract_pala_details(soup):\n",
    "    palas = []\n",
    "    pala_items = soup.select(\"li.item.product.product-item\")\n",
    "\n",
    "    for item in pala_items:\n",
    "        # Nombre y precio de la pala\n",
    "        name = item.select_one(\"strong.product-item-name a\").text.strip()\n",
    "        price = item.select_one(\"span.price-wrapper\").text.strip()\n",
    "        details_url = item.select_one(\"strong.product-item-name a\")[\"href\"]\n",
    "\n",
    "        # Detalles adicionales desde la página de la pala\n",
    "        details_html = get_html(details_url)\n",
    "        details_soup = BeautifulSoup(details_html, \"html.parser\")\n",
    "\n",
    "        # Atributos de la pala\n",
    "        attributes_div = details_soup.select_one(\"div#product\\\\.attributes\\\\.tab\")\n",
    "        attributes = {}\n",
    "        if attributes_div:\n",
    "            for attr in attributes_div.select(\"div.description-attributes\"):\n",
    "                label = attr.select_one(\"span.description-attributes-label\").text.strip()\n",
    "                value = attr.select_one(\"span.description-attributes-value\").text.strip()\n",
    "                attributes[label] = value\n",
    "\n",
    "        # Descripción de la pala\n",
    "        description_div = details_soup.select_one(\"div.product.attribute.description div.value\")\n",
    "        description = description_div.text.strip() if description_div else \"\"\n",
    "\n",
    "        # Guardar información de la pala\n",
    "        palas.append({\n",
    "            \"name\": name,\n",
    "            \"price\": price,\n",
    "            \"attributes\": attributes,\n",
    "            \"description\": description,\n",
    "        })\n",
    "\n",
    "    return palas\n",
    "\n",
    "# Función principal para recorrer todas las páginas\n",
    "def main():\n",
    "    all_palas = []\n",
    "    try:\n",
    "        for page in range(1, 36):  # Iterar sobre las 40 páginas\n",
    "            print(f\"Procesando página {page}...\")\n",
    "            url = BASE_URL.format(page)\n",
    "            html = get_html(url)\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            palas = extract_pala_details(soup)\n",
    "            all_palas.extend(palas)\n",
    "            time.sleep(1)  # Evitar ser bloqueado por demasiadas solicitudes\n",
    "\n",
    "        # Guardar los datos en un archivo JSON\n",
    "        with open(\"data/palas.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_palas, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(\"Datos guardados en palas.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Nombre del archivo donde se guardaron los datos\n",
    "FILENAME = \"palas.json\"\n",
    "\n",
    "# Leer y mostrar los datos del archivo JSON\n",
    "def print_palas():\n",
    "    try:\n",
    "        with open(FILENAME, \"r\", encoding=\"utf-8\") as f:\n",
    "            palas = json.load(f)\n",
    "        \n",
    "        # Imprimir los datos de cada pala\n",
    "        for i, pala in enumerate(palas, 1):\n",
    "            print(f\"Pala {i}:\")\n",
    "            print(f\"  Nombre: {pala['name']}\")\n",
    "            print(f\"  Precio: {pala['price']}\")\n",
    "            print(f\"  Descripción: {pala['description']}\\n\")\n",
    "            print(\"  Atributos:\")\n",
    "            for attr, value in pala[\"attributes\"].items():\n",
    "                print(f\"    - {attr}: {value}\")\n",
    "            print(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo '{FILENAME}' no existe.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al leer el archivo JSON: {e}\")\n",
    "\n",
    "# Ejecutar la función\n",
    "print_palas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping de Palas en Keepadel  \n",
    "\n",
    "- Este script extrae información de palas de pádel desde **Keepadel** usando `requests` y `BeautifulSoup`.  \n",
    "- Obtiene el HTML de la página de productos y extrae **nombre, precio, enlace y descripciones**.  \n",
    "- Para cada pala, accede a su página individual y obtiene una **descripción detallada**.  \n",
    "- Recorre la página principal y guarda la información en `keepadel_palas.json`.  \n",
    "- Incluye un `time.sleep(1)` para evitar bloqueos por exceso de solicitudes.  \n",
    "- Imprime los datos recopilados en la consola antes de guardarlos en JSON.  \n",
    "- Se recomienda respetar los **términos de uso** del sitio web al hacer scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# URL base de las páginas de palas\n",
    "BASE_URL = \"https://keepadel.com/es/9-palas-de-padel?resultsPerPage=99999\"\n",
    "\n",
    "# Encabezados para la solicitud HTTP\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Función para obtener el HTML de la página\n",
    "def get_html(url):\n",
    "    response = requests.get(url, headers=HEADERS, verify=False)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Error al acceder a la página: {response.status_code}\")\n",
    "\n",
    "# Función para extraer los detalles de cada pala\n",
    "def extract_pala_details(soup):\n",
    "    palas = []\n",
    "    pala_items = soup.select(\"div.js-product-miniature-wrapper\")\n",
    "\n",
    "    for item in pala_items:\n",
    "        # Nombre, precio y enlace de la pala\n",
    "        name_element = item.select_one(\"h2.product-title a\")\n",
    "        name = name_element.text.strip() if name_element else \"Nombre no disponible\"\n",
    "\n",
    "        price_element = item.select_one(\"div.product-price-and-shipping span.product-price\")\n",
    "        price = price_element[\"content\"] if price_element and price_element.has_attr(\"content\") else \"Precio no disponible\"\n",
    "\n",
    "        details_url = name_element['href'] if name_element else \"URL no disponible\"\n",
    "\n",
    "        # Descripción breve desde la página principal\n",
    "        short_description_element = item.select_one(\"div.product-description-short a\")\n",
    "        short_description = short_description_element.text.strip() if short_description_element else \"Descripción breve no disponible\"\n",
    "\n",
    "        # Detalles adicionales desde la página de la pala\n",
    "        full_description = \"Descripción completa no disponible\"\n",
    "        if details_url != \"URL no disponible\":\n",
    "            try:\n",
    "                details_html = get_html(details_url)\n",
    "                details_soup = BeautifulSoup(details_html, \"html.parser\")\n",
    "\n",
    "                # Descripción detallada de la pala\n",
    "                description_div = details_soup.select_one(\"#productdaas-accordion-description .rte-content\")\n",
    "                if description_div:\n",
    "                    full_description = description_div.get_text(strip=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {details_url}: {e}\")\n",
    "\n",
    "        # Guardar información de la pala\n",
    "        palas.append({\n",
    "            \"name\": name,\n",
    "            \"price\": price,\n",
    "            \"link\": details_url,\n",
    "            \"short_description\": short_description,\n",
    "            \"full_description\": full_description,\n",
    "        })\n",
    "\n",
    "    return palas\n",
    "\n",
    "# Función principal para recorrer todas las páginas\n",
    "def main():\n",
    "    all_palas = []\n",
    "    try:\n",
    "        for page in range(1, 2):  # Cambiar el rango según el número de páginas\n",
    "            print(f\"Procesando página {page}...\")\n",
    "            url = BASE_URL.format(page)\n",
    "            html = get_html(url)\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            palas = extract_pala_details(soup)\n",
    "            all_palas.extend(palas)\n",
    "            time.sleep(1)  # Evitar ser bloqueado por demasiadas solicitudes\n",
    "\n",
    "        # Imprimir los datos recopilados\n",
    "        for idx, pala in enumerate(all_palas, start=1):\n",
    "            print(f\"Pala {idx}:\")\n",
    "            print(f\"  Nombre: {pala['name']}\")\n",
    "            print(f\"  Precio: {pala['price']}\")\n",
    "            print(f\"  Enlace: {pala['link']}\")\n",
    "            print(f\"  Descripción breve: {pala['short_description']}\")\n",
    "            print(f\"  Descripción completa: {pala['full_description']}\\n\")\n",
    "\n",
    "        # Guardar los datos en un archivo JSON\n",
    "        with open(\"data/keepadel_palas.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_palas, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(\"Datos guardados en keepadel_palas.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padel Mania\n",
    "\n",
    "- Este script extrae información de palas de pádel desde **Padelmania** usando `requests` y `BeautifulSoup`.  \n",
    "- Obtiene el HTML de cada página y extrae **nombre, precio, marca, enlace y descripciones**.  \n",
    "- Para cada pala, accede a su página individual y obtiene una **descripción completa y detalles del producto**.  \n",
    "- Recorre hasta **72 páginas**, recopilando toda la información disponible.  \n",
    "- Incluye un `time.sleep(1)` para evitar bloqueos por exceso de solicitudes.  \n",
    "- Imprime los datos recopilados en la consola y los guarda en `padelmania_palas.json`.  \n",
    "- Se recomienda respetar los **términos de uso** del sitio web al hacer scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# URL base de las páginas de palas\n",
    "BASE_URL = \"https://padelmania.com/es/5-palas-de-padel?resultsPerPage=99999&page={}\"\n",
    "\n",
    "# Encabezados para la solicitud HTTP\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Función para obtener el HTML de la página\n",
    "def get_html(url):\n",
    "    response = requests.get(url, headers=HEADERS, verify=False)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Error al acceder a la página: {response.status_code}\")\n",
    "\n",
    "# Función para extraer los detalles de cada pala\n",
    "def extract_pala_details(soup):\n",
    "    palas = []\n",
    "    pala_items = soup.select(\"div.js-product-miniature-wrapper\")\n",
    "\n",
    "    for item in pala_items:\n",
    "        # Nombre, precio y enlace de la pala\n",
    "        name_element = item.select_one(\"h2.product-title a\")\n",
    "        name = name_element.text.strip() if name_element else \"Nombre no disponible\"\n",
    "\n",
    "        price_element = item.select_one(\"div.product-price-and-shipping span.product-price\")\n",
    "        price = price_element[\"content\"] if price_element and price_element.has_attr(\"content\") else \"Precio no disponible\"\n",
    "\n",
    "        details_url = name_element['href'] if name_element else \"URL no disponible\"\n",
    "\n",
    "        # Marca de la pala\n",
    "        brand_element = item.select_one(\"div.product-brand a\")\n",
    "        brand = brand_element.text.strip() if brand_element else \"Marca no disponible\"\n",
    "\n",
    "        # Descripción breve desde la página principal\n",
    "        short_description_element = item.select_one(\"div.product-description-short a\")\n",
    "        short_description = short_description_element.text.strip() if short_description_element else \"Descripción breve no disponible\"\n",
    "\n",
    "        # Detalles adicionales desde la página de la pala\n",
    "        details_html = get_html(details_url) if details_url != \"URL no disponible\" else \"\"\n",
    "        details_soup = BeautifulSoup(details_html, \"html.parser\") if details_html else None\n",
    "\n",
    "        # Descripción completa desde el div específico\n",
    "        description_div = details_soup.select_one(\"#productdaas-accordion-description .rte-content\") if details_soup else None\n",
    "        full_description = description_div.text.strip() if description_div else \"Descripción completa no disponible\"\n",
    "\n",
    "        # Detalles adicionales del producto\n",
    "        details_div = details_soup.select_one(\"#productdaas-accordion-details\") if details_soup else None\n",
    "        product_details = details_div.text.strip() if details_div else \"Detalles del producto no disponibles\"\n",
    "\n",
    "        # Guardar información de la pala\n",
    "        palas.append({\n",
    "            \"name\": name,\n",
    "            \"price\": price,\n",
    "            \"link\": details_url,\n",
    "            \"brand\": brand,\n",
    "            \"short_description\": short_description,\n",
    "            \"full_description\": full_description,\n",
    "            \"product_details\": product_details\n",
    "        })\n",
    "\n",
    "    return palas\n",
    "\n",
    "# Función principal para recorrer todas las páginas\n",
    "def main():\n",
    "    all_palas = []\n",
    "    try:\n",
    "        for page in range(1, 72):  # Cambiar el rango según el número de páginas\n",
    "            print(f\"Procesando página {page}...\")\n",
    "            url = BASE_URL.format(page)\n",
    "            html = get_html(url)\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            palas = extract_pala_details(soup)\n",
    "            all_palas.extend(palas)\n",
    "            time.sleep(1)  # Evitar ser bloqueado por demasiadas solicitudes\n",
    "\n",
    "        # Imprimir los datos recopilados\n",
    "        for idx, pala in enumerate(all_palas, start=1):\n",
    "            print(f\"Pala {idx}:\")\n",
    "            print(f\"  Nombre: {pala['name']}\")\n",
    "            print(f\"  Precio: {pala['price']}\")\n",
    "            print(f\"  Enlace: {pala['link']}\")\n",
    "            print(f\"  Marca: {pala['brand']}\")\n",
    "            print(f\"  Descripción breve: {pala['short_description']}\")\n",
    "            print(f\"  Descripción completa: {pala['full_description']}\")\n",
    "            print(f\"  Detalles del producto: {pala['product_details']}\\n\")\n",
    "\n",
    "        # Guardar los datos en un archivo JSON\n",
    "        with open(\"data/padelmania_palas.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_palas, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(\"Datos guardados en padelmania_palas.json\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unificación de Datos de Palas de Pádel  \n",
    "\n",
    "- Este script carga datos de palas desde **tres fuentes diferentes** (`Padel Nuestro`, `Keepadel` y `Padelmania`).  \n",
    "- Usa `json.load()` para leer los archivos `palas.json`, `keepadel_palas.json` y `padelmania_palas.json`.  \n",
    "- Extrae y normaliza los datos, incluyendo **nombre, precio, atributos, descripción y fuente** de cada pala.  \n",
    "- Asegura que los atributos opcionales no queden vacíos, manejando posibles errores de codificación o JSON.  \n",
    "- Genera un archivo final `palas_unificadas.json` con **toda la información consolidada**.  \n",
    "- Si hay errores al procesar los archivos, los muestra en consola para su depuración.  \n",
    "- Se recomienda verificar la estructura de los JSON antes de ejecutar el script.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def unificar_datos():\n",
    "    try:\n",
    "        with open('data/palas.json', encoding=\"utf-8\") as f1, \\\n",
    "             open('data/keepadel_palas.json', encoding=\"utf-8\") as f2, \\\n",
    "             open('data/padelmania_palas.json', encoding=\"utf-8\") as f3:\n",
    "            \n",
    "            palas1 = json.load(f1)\n",
    "            palas2 = json.load(f2)\n",
    "            palas3 = json.load(f3)\n",
    "\n",
    "            palas = []\n",
    "\n",
    "            # Procesar cada JSON\n",
    "            for pala in palas1:\n",
    "                palas.append({\n",
    "                    \"name\": pala[\"name\"],\n",
    "                    \"price\": pala[\"price\"],\n",
    "                    \"attributes\": pala.get(\"attributes\", None),  # Evitar valores vacíos innecesarios\n",
    "                    \"description\": pala[\"description\"],\n",
    "                    \"source\": \"https://www.padelnuestro.com/int/padel-rackets?\"\n",
    "                })\n",
    "\n",
    "            for pala in palas2:\n",
    "                palas.append({\n",
    "                    \"name\": pala[\"name\"],\n",
    "                    \"price\": pala[\"price\"],\n",
    "                    \"attributes\": None,  # No tiene atributos\n",
    "                    \"description\": pala[\"full_description\"],\n",
    "                    \"source\": \"https://keepadel.com/es/9-palas-de-padel\"\n",
    "                })\n",
    "\n",
    "            for pala in palas3:\n",
    "                palas.append({\n",
    "                    \"name\": pala[\"name\"],\n",
    "                    \"price\": pala[\"price\"],\n",
    "                    \"attributes\": pala.get(\"product_details\", None),  # Evita valores vacíos\n",
    "                    \"description\": pala[\"full_description\"],\n",
    "                    \"source\": \"https://padelmania.com/es/5-palas-de-padel\"\n",
    "                })\n",
    "\n",
    "            return palas\n",
    "\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error de codificación: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al cargar JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")\n",
    "    return []\n",
    "\n",
    "# Ejecutar función y guardar los datos\n",
    "palas = unificar_datos()\n",
    "\n",
    "if palas:\n",
    "    with open('data/palas_unificadas.json', 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(palas, f, indent=4, ensure_ascii=False)  # `ensure_ascii=False` para caracteres especiales\n",
    "    print(f\"Se han guardado {len(palas)} palas en 'data/palas_unificadas.json'\")\n",
    "else:\n",
    "    print(\"No se han podido unificar los datos.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo IA Palas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "from docx import Document\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación y Búsqueda de Embeddings con Azure OpenAI  \n",
    "\n",
    "- Este script procesa **textos largos** dividiéndolos en *chunks* con solapamiento para mejorar la segmentación.  \n",
    "- Utiliza `OpenAIEmbeddings` de **Azure OpenAI** para convertir los *chunks* en vectores de embeddings.  \n",
    "- Los embeddings se generan con el modelo `\"text-embedding-ada-002\"`, utilizando la API de Azure OpenAI.  \n",
    "- Para buscar información relevante, calcula la **similitud del coseno** entre la consulta y los *chunks* almacenados.  \n",
    "- Ordena los resultados por relevancia y devuelve los **top-k segmentos** más similares a la consulta.  \n",
    "- Incluye un ejemplo práctico con un texto de prueba y una consulta sobre palas de pádel.  \n",
    "- Es necesario configurar correctamente las credenciales (`API_KEY`, `API_BASE`, `API_VERSION`) antes de ejecutar.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Función para dividir el texto en chunks\n",
    "def split_text_into_chunks(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"\n",
    "    Divide un texto largo en chunks de tamaño específico con un solapamiento opcional.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# Función para generar embeddings usando Azure OpenAI\n",
    "def generate_embeddings_azure(chunks, api_key, api_base, api_version, deployment):\n",
    "    \"\"\"\n",
    "    Genera embeddings para una lista de chunks de texto utilizando Azure OpenAI.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        deployment=deployment,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        openai_api_key=api_key,\n",
    "        openai_api_base=api_base,\n",
    "        openai_api_version=api_version\n",
    "    )\n",
    "    chunk_vectors = []\n",
    "    for chunk in chunks:\n",
    "        vector = embeddings.embed_query(chunk)\n",
    "        chunk_vectors.append({\"chunk\": chunk, \"vector\": vector})\n",
    "    return chunk_vectors\n",
    "\n",
    "# Función para buscar información relevante manualmente\n",
    "def search_relevant_chunks(query, chunk_vectors, api_key, api_base, api_version, deployment, top_k=5):\n",
    "    \"\"\"\n",
    "    Busca los chunks más relevantes para una consulta utilizando la similitud de coseno.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        deployment=deployment,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "        openai_api_base=AZURE_OPENAI_ENDPOINT,\n",
    "        openai_api_version=OPENAI_API_VERSION\n",
    "    )\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "    \n",
    "    # Calcular similitudes por coseno\n",
    "    similarities = []\n",
    "    for chunk_data in chunk_vectors:\n",
    "        chunk_vector = chunk_data[\"vector\"]\n",
    "        similarity = np.dot(query_vector, chunk_vector) / (np.linalg.norm(query_vector) * np.linalg.norm(chunk_vector))\n",
    "        similarities.append((chunk_data[\"chunk\"], similarity))\n",
    "    \n",
    "    # Ordenar por relevancia\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Texto de ejemplo\n",
    "    documentation_text = \"Este es un texto de ejemplo que representa la documentación para buscar la pala ideal.\" * 20\n",
    "\n",
    "    # Dividir en chunks\n",
    "    chunks = split_text_into_chunks(documentation_text)\n",
    "\n",
    "    AZURE_OPENAI_API_KEY = \"AZURE_OPENAI_API_KEY\"\n",
    "    AZURE_OPENAI_ENDPOINT = \"AZURE_OPENAI_ENDPOINT\"\n",
    "    OPENAI_API_VERSION = \"2023-05-15\"\n",
    "    # Configuración de Azure OpenAI\n",
    "    \n",
    "    EMBEDDING_DEPLOYMENT = \"text-embedding-ada-002\"\n",
    "\n",
    "    # Generar embeddings para los chunks\n",
    "    chunk_vectors = generate_embeddings_azure(chunks, AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, OPENAI_API_VERSION, EMBEDDING_DEPLOYMENT)\n",
    "    print(\"Embeddings generados para los chunks.\")\n",
    "\n",
    "    # Consulta del usuario\n",
    "    query = \"Soy un jugador intermedio que busca una pala con control y potencia moderada.\"\n",
    "\n",
    "    # Buscar chunks relevantes\n",
    "    top_chunks = search_relevant_chunks(query, chunk_vectors, AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, OPENAI_API_VERSION, EMBEDDING_DEPLOYMENT)\n",
    "    print(\"\\nChunks más relevantes:\")\n",
    "    for i, (chunk, similarity) in enumerate(top_chunks):\n",
    "        print(f\"{i + 1}. Similitud: {similarity:.4f}\")\n",
    "        print(f\"Chunk: {chunk}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asistente de Pádel con Azure OpenAI  \n",
    "\n",
    "- Este script utiliza **Azure OpenAI** para recomendar una pala de pádel basada en características del jugador.  \n",
    "- Carga un documento Word con información sobre la elección de palas y lo usa como referencia.  \n",
    "- El asistente considera **nivel de juego, estilo de juego y lesiones** para hacer recomendaciones personalizadas.  \n",
    "- Genera una respuesta en **formato JSON**, incluyendo aspectos clave como **forma, peso, balance y materiales**.  \n",
    "- Utiliza `gpt-35-turbo` para procesar la consulta del jugador y devolver una recomendación óptima.  \n",
    "- Es necesario configurar correctamente las credenciales (`API_KEY`, `API_BASE`, `API_VERSION`) antes de ejecutar.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Configuración de Azure OpenAI\n",
    "AZURE_OPENAI_API_KEY = \"AZURE_OPENAI_API_KEY\"\n",
    "AZURE_OPENAI_ENDPOINT = \"AZURE_OPENAI_ENDPOINT\"\n",
    "OPENAI_API_VERSION = \"2023-05-15\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "# Ruta del archivo Word\n",
    "file_path = r\"C:\\Users\\jgutierrezdecalderon\\OneDrive - KPMG\\Desktop\\Personal\\Proyectos\\Padel_chatbot\\Documentacion_elleccion_pala.docx\"\n",
    "\n",
    "# Leer el contenido del archivo Word\n",
    "def read_word_file(file_path):\n",
    "    doc = Document(file_path)\n",
    "    content = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs if paragraph.text.strip()])\n",
    "    return content\n",
    "\n",
    "# Extraer contenido del archivo\n",
    "document_content = read_word_file(file_path)\n",
    "\n",
    "# Variables del jugador (estas pueden venir de un formulario o sistema externo)\n",
    "nivel_juego = 5  # Nivel del jugador: 0 (principiante) a 7 (avanzado/pro)\n",
    "tipo_jugador = \"potencia\"  # Puede ser \"control\", \"equilibrado\" o \"potencia\"\n",
    "lesion_codo = \"si\"  # Puede ser \"si\" o \"no\"\n",
    "\n",
    "propt_assistant_padel=\"\"\"Eres un asistente de pádel que ayuda a los jugadores a elegir la pala ideal para su juego. \n",
    "Debes tener en cuenta el nivel de juego, el tipo de jugador y si tiene lesión de codo. \n",
    "Configura la pala recomendada en base a estos criterios en cuanto a forma, peso, material, grosor, balance y superficie. \n",
    "Usa la documentación proporcionada para reforzar tus recomendaciones.\n",
    "Ten en cuenta también la descripción de la pala que te da el jugador o de su necesidad en la pregunta\n",
    "\n",
    "El nivel de juego del jugador es {nivel_juego} sobre 7\n",
    "El tipo de jugador es {tipo_jugador}\n",
    "Tiene lesión de codo. {lesion_codo}\n",
    "\n",
    "La respuesta será en formato json poniendo la recomendación de cada componente\"\"\"\n",
    "\n",
    "\n",
    "# Crear el prompt para el asistente\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": propt_assistant_padel },\n",
    "        {\"role\": \"system\", \"content\": f\"Documentación sobre la elección de pala:\\n{document_content}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Soy un jugador de dercha que es algo agresivo, me gusta que la pelota coja efectos pero sentirme cómo desde atrás\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Recomendaciones generadas por el asistente\n",
    "recomendaciones = json.loads(response.choices[0].message.content)\n",
    "print(recomendaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de embeddings\n",
    "\n",
    "\n",
    "- Carga un archivo JSON que contiene información sobre palas (palas_unificadas.json).\n",
    "- Define una ruta de archivo para guardar los embeddings generados (palas_embeddings.json).\n",
    "- Utiliza la API de OpenAI para generar embeddings a partir de descripciones de palas.\n",
    "- Verifica si existen embeddings previamente generados y los carga si es necesario.\n",
    "- Filtra las palas ya procesadas para evitar duplicados en los embeddings.\n",
    "- Solo genera embeddings para aquellas palas que tienen descripción y no han sido procesadas antes.\n",
    "- Guarda los embeddings generados en un archivo JSON para su uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Cargar el JSON de las palas\n",
    "with open(\"data/palas_unificadas.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    palas_data = json.load(file)\n",
    "\n",
    "# Ruta para guardar los embeddings\n",
    "EMBEDDINGS_FILE = \"palas_embeddings.json\"\n",
    "\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"):  # model = \"deployment_name\"\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Función para generar embeddings para cada pala\n",
    "def generar_embeddings_palas(palas, embeddings_file):\n",
    "    # Cargar embeddings existentes si el archivo ya existe\n",
    "    if os.path.exists(embeddings_file):\n",
    "        with open(embeddings_file, \"r\", encoding=\"utf-8\") as ef:\n",
    "            embeddings = json.load(ef)\n",
    "    else:\n",
    "        embeddings = []\n",
    "\n",
    "    # Crear un set con los IDs de las palas ya procesadas\n",
    "    procesadas = {item[\"pala\"][\"name\"] for item in embeddings}\n",
    "\n",
    "    # Generar embeddings solo para palas nuevas\n",
    "    for pala in palas:\n",
    "        if pala[\"name\"] not in procesadas:\n",
    "            description = pala.get(\"description\", \"\")\n",
    "            if description:  # Solo generamos embeddings si hay descripción\n",
    "                embedding = generate_embeddings(description)\n",
    "                embeddings.append({\"pala\": pala, \"embedding\": embedding})\n",
    "\n",
    "    # Guardar embeddings actualizados\n",
    "    with open(embeddings_file, \"w\", encoding=\"utf-8\") as ef:\n",
    "        json.dump(embeddings, ef, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Generar y guardar embeddings\n",
    "embeddings_palas = generar_embeddings_palas(palas_data, EMBEDDINGS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_por_precio(embeddings_file, min_price, max_price):\n",
    "    # Leer el archivo de embeddings\n",
    "    with open(embeddings_file, \"r\", encoding=\"utf-8\") as ef:\n",
    "        embeddings = json.load(ef)\n",
    "\n",
    "    # Filtrar las palas por rango de precios\n",
    "    palas_filtradas = []\n",
    "    for item in embeddings:\n",
    "        try:\n",
    "            precio = float(item[\"pala\"][\"price\"].strip(\"€\").replace(\",\", \".\"))\n",
    "            if min_price <= precio <= max_price:\n",
    "                palas_filtradas.append(item)\n",
    "        except ValueError:\n",
    "            continue  # Si no se puede procesar el precio, ignorar la pala\n",
    "\n",
    "    return palas_filtradas\n",
    "\n",
    "# Definir rango de precios\n",
    "min_price = 50  # Precio mínimo\n",
    "max_price = 200  # Precio máximo\n",
    "\n",
    "# Filtrar palas por precio utilizando el archivo de embeddings\n",
    "embeddings_palas_filtradas = filtrar_por_precio(EMBEDDINGS_FILE, min_price, max_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda por similitud\n",
    "\n",
    "- cosine_similarity(a, b): Calcula la similitud coseno entre dos vectores a y b para medir su semejanza. Se utiliza la fórmula estándar del coseno de los ángulos entre los vectores.\n",
    "\n",
    "- get_embedding(text, model): Genera un embedding para un texto proporcionado utilizando el modelo de OpenAI (por defecto, text-embedding-ada-002). Los embeddings son representaciones numéricas del texto.\n",
    "\n",
    "- buscar_palas_por_similitud(consulta, embeddings_palas, top_n): Realiza una búsqueda de las palas más similares a una consulta de texto:\n",
    "\n",
    "- Genera un embedding para la consulta.\n",
    "Calcula la similitud coseno entre el embedding de la consulta y los embeddings de las palas.\n",
    "Ordena los resultados por similitud en orden descendente.\n",
    "Devuelve las top_n palas más similares.\n",
    "Consulta del usuario: El código simula una consulta con texto (especificando las condiciones para buscar una pala), que se utiliza en la función de búsqueda.\n",
    "\n",
    "- Mostrar resultados: Imprime los resultados de las palas más similares, mostrando el nombre, la similitud, el precio y la fuente de cada pala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):  # model = \"deployment_name\"\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "def buscar_palas_por_similitud(consulta, embeddings_palas, top_n=5):\n",
    "    # Generar embedding para la consulta\n",
    "    consulta_embedding = get_embedding(consulta, model=\"text-embedding-ada-002\")\n",
    "\n",
    "    # Calcular similitud entre la consulta y las palas\n",
    "    resultados = []\n",
    "    for item in embeddings_palas:\n",
    "        pala = item[\"pala\"]\n",
    "        embedding = item[\"embedding\"]\n",
    "        similitud = cosine_similarity(consulta_embedding, embedding)\n",
    "        resultados.append({\"pala\": pala, \"similitud\": similitud})\n",
    "\n",
    "    # Ordenar por similitud descendente\n",
    "    resultados_ordenados = sorted(resultados, key=lambda x: x[\"similitud\"], reverse=True)\n",
    "    return resultados_ordenados[:top_n]\n",
    "\n",
    "\n",
    "# Consulta del usuario\n",
    "consulta = \"\"\"\n",
    "Ayudame a buscar la pala que más se ajuste a estas condiciones:\n",
    "{recomendaciones}\n",
    "\"\"\"\n",
    "\n",
    "# Realizar búsqueda\n",
    "top_palas = buscar_palas_por_similitud(consulta, embeddings_palas_filtradas, top_n=10)\n",
    "\n",
    "# Mostrar resultados\n",
    "for i, result in enumerate(top_palas, 1):\n",
    "    print(f\"{i}. {result['pala']['name']} - Similitud: {result['similitud']:.2f} - Precio: {result['pala']['price']} - Web {result['pala']['source']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
